[{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/ground_truth:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"ground_truth","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Ground truth","code_version":"build_main","method_summary":"Returns the ground truth predictions.","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/ground_truth","method_description":"The identity function that returns the ground-truth information as the output.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/methods/jn_ap_op2:build_main","task_id":"methods","code_url":"https://github.com/AntoinePassemiers/Open-Challenges-Single-Cell-Perturbations","method_id":"jn_ap_op2","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"JN-AP-OP2","code_version":"build_main","method_summary":"Deep learning architecture composed of 2 modules: a sample-centric MLP and a gene-centric MLP","references_doi":null,"documentation_url":"https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/discussion/461159","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/jn_ap_op2","method_description":"We first encode each sample using leave-one-out encoder based on compound and cell type. This produces X with the dimension of n_samples, n_genes, n_encode,\nwhere n_encode is 2. Then, X is passed to a MLP1 sample-wise with input of n_samples, n_genes*n_encode, which outputs the same dimension data.\nThe purpose of this MLP is to learn inter-gene relationships. Then, we group the output of MLP1 with X (original encoded data) and feed it\nto MLP2 which receives n_smaples*n_genes, (n_encode + n_encode) and results n_samples*n_genes. This MLP2 trains on each (compound, cell_type, gene)\ncombination. This is to overcome the underdetermination problem due to lack of sufficient (compound, cell_type) samples.\n"},{"image":"https://github.com/orgs/openproblems-bio/packages?repo_name=task_perturbation_prediction&q=methods/lgc_ensemble","task_id":"methods","code_url":"https://github.com/Jean-KOUAGOU/1st-place-solution-single-cell-pbs/tree/main","method_id":"lgc_ensemble","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"LSTM-GRU-CNN Ensemble","code_version":"build_main","method_summary":"An ensemble of LSTM, GRU, and 1D CNN models","references_doi":null,"documentation_url":"https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/discussion/459258","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/lgc_ensemble","method_description":"An ensemble of LSTM, GRU, and 1D CNN models with a variety of input features derived from ChemBERTa embeddings,\none-hot encoding of cell type/small molecule pairs, and various statistical measures of target gene expression.\nThe models were trained with a combination of MSE, MAE, LogCosh, and BCE loss functions to improve their\nrobustness and predictive performance. The approach also included data augmentation techniques to ensure\ngeneralization and account for noise in the data.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/mean_across_celltypes:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"mean_across_celltypes","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Mean per cell type and gene","code_version":"build_main","method_summary":"Baseline method that returns mean of cell type's outcomes","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/mean_across_celltypes","method_description":"Baseline method that predicts for a cell type the mean of its outcomes of all compounds.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/mean_across_compounds:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"mean_across_compounds","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Mean per compound and gene","code_version":"build_main","method_summary":"Baseline method that returns mean of compound's outcomes","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/mean_across_compounds","method_description":"Baseline method that predicts for a compound the mean of its outcomes of all samples.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/mean_outcome:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"mean_outcome","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Mean per gene","code_version":"build_main","method_summary":"Baseline method that returns mean of gene's outcomes","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/mean_outcome","method_description":"Baseline method that predicts for a gene the mean of its outcomes of all samples.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/methods/nn_retraining_with_pseudolabels:build_main","task_id":"methods","code_url":"https://github.com/okon2000/single_cell_perturbations","method_id":"nn_retraining_with_pseudolabels","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"NN retraining with pseudolabels","code_version":"build_main","method_summary":"Neural networks with pseudolabeling and ensemble modelling","references_doi":null,"documentation_url":"https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/discussion/458750","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/nn_retraining_with_pseudolabels","method_description":"The prediction system is two staged, so I publish two versions of the notebook.\nThe first stage predicts pseudolabels. To be honest, if I stopped on this version, I would not be the third.\nThe predicted pseudolabels on all test data (255 rows) are added to training in the second stage.\n\n**Stage 1 preparing pseudolabels**: The main part of this system is a neural network. Every neural network and its environment was optimized by optuna. Hyperparameters that have been optimized:\na dropout value, a number of neurons in particular layers, an output dimension of an embedding layer, a number of epochs, a learning rate, a batch size, a number of dimension of truncated singular value decomposition.\nThe optimization was done on custom 4-folds cross validation. In order to avoid overfitting to cross validation by optuna I applied 2 repeats for every fold and took an average. Generally, the more, the better. The optuna's criterion was MRRMSE.\nFinally, 7 models were ensembled. Optuna was applied again to determine best weights of linear combination. The prediction of test set is the pseudolabels now and will be used in second stage.\n\n**Stage 2 retraining with pseudolabels**: The pseudolabels (255 rows) were added to the training dataset. I applied 20 models with optimized parameters in different experiments for a model diversity.\nOptuna selected optimal weights for the linear combination of the prediction again.\nModels had high variance, so every model was trained 10 times on all dataset and the median of prediction is taken as a final prediction. The prediction was additionally clipped to colwise min and max. \n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/methods/pyboost:build_main","task_id":"methods","code_url":"https://github.com/Ambros-M/Single-Cell-Perturbations-2023","method_id":"pyboost","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"Py-boost","code_version":"build_main","method_summary":"Py-boost predicting t-scores","references_doi":null,"documentation_url":"https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/discussion/458661","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/pyboost","method_description":"An ensemble of four models was considered: \n\n* Py-boost (a ridge regression-based recommender system)\n* ExtraTrees (a decision tree ensemble with target-encoded features)\n* a k-nearest neighbors recommender system\n* a ridge regression model\n\nEach model offered distinct strengths and weaknesses: ExtraTrees and\nknn were unable to extrapolate beyond the training data, while ridge\nregression provided extrapolation capability. To enhance model performance,\ndata augmentation techniques were used, including averaging differential\nexpressions for compound mixtures and adjusting cell counts to reduce biases.\n\nIn the end, only the py-boost model is used for generating predictions.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/sample:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"sample","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Sample","code_version":"build_main","method_summary":"Sample predictions from the training data","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/sample","method_description":"This method samples the training data to generate predictions.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/methods/scape:build_main","task_id":"methods","code_url":"https://github.com/scapeML/scape","method_id":"scape","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"ScAPE","code_version":"build_main","method_summary":"Neural network model for drug effect prediction","references_doi":null,"documentation_url":"https://docs.google.com/document/d/1w0GIJ8VoQx3HEJNmLXoU-Y_STB-h5-bXusL80_6EVuU/edit","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/scape","method_description":"ScAPE is utilises a neural network (NN) model to estimate drug effects on gene expression in\nperipheral blood mononuclear cells (PBMCs). The model took drug and cell features as input,\nwith these features primarily derived from the median of signed log-pvalues and log fold-changes\ngrouped by drug and cell type. The NN was trained using a leave-one-drug-out cross-validation\nstrategy, focusing on NK cells as a representative cell type due to their similarity to B cells\nand Myeloid cells in principal component analysis. Model performance was evaluated by comparing\nits predictions against two baselines: predicting zero effect and predicting the median\nlog-pvalue for each drug. The final submission combined predictions from models trained on\ndifferent gene and drug subsets, aiming to enhance overall prediction accuracy.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/methods/transformer_ensemble:build_main","task_id":"methods","code_url":"https://github.com/Eliorkalfon/single_cell_pb","method_id":"transformer_ensemble","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": false,"method_name":"Transformer Ensemble","code_version":"build_main","method_summary":"An ensemble of four transformer models, trained on diverse feature sets, with a cluster-based sampling strategy and robust validation for optimal performance.","references_doi":null,"documentation_url":"https://www.kaggle.com/competitions/open-problems-single-cell-perturbations/discussion/458738","references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/methods/transformer_ensemble","method_description":"This method employs an ensemble of four transformer models,\neach with different weights and trained on slightly varying feature sets.\nThe feature engineering process involved one-hot encoding of categorical labels,\ntarget encoding using mean and standard deviation, and enriching the feature set\nwith the standard deviation of target variables. Additionally, the dataset was\ncarefully examined to ensure data cleanliness. A sophisticated sampling strategy\nbased on K-Means clustering was employed to partition the data into training and\nvalidation sets, ensuring a representative distribution. The model architecture\nleveraged sparse and dense feature encoding, along with a transformer for effective\nlearning.\n"},{"image":"https://ghcr.io/openproblems-bio/task_perturbation_prediction/control_methods/zeros:build_main","task_id":"control_methods","code_url":"https://github.com/openproblems-bio/task_perturbation_prediction","method_id":"zeros","commit_sha":"2fa44462b1e7d530bad703c4a20ed22b49d3705e","is_baseline": true,"method_name":"Zeros","code_version":"build_main","method_summary":"Baseline method that predicts all zeros","references_doi":null,"documentation_url":null,"references_bibtex":null,"implementation_url":"https://github.com/openproblems-bio/task_perturbation_prediction/blob/2fa44462b1e7d530bad703c4a20ed22b49d3705e/src/control_methods/zeros","method_description":"Baseline method that predicts all zeros.\n"}]